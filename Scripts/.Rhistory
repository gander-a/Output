guides(fill=guide_legend(title="Change"))
plot(g)
pngname = sprintf("C:/Users/Armin/Desktop/Data Science/CSH Project/Colex_vader/Runoncluster/PlotsCluster/coha2_change_%s.png", folder)
ggsave(pngname, width = 30, height = 20, units = "cm")
}
# Thick lines plot
g = ggplot(agg, aes(x=dec2, y=meansim, group = dec1, color = dec1)) +
geom_line(lwd = 3, alpha = 0.7) +
geom_point(size = 5, alpha = 0.7) +
ggtitle("Similarity between decades") +
xlab("") + ylab("Average similarity") +
theme(panel.grid.minor = element_blank(),panel.background = element_blank(),
axis.line = element_line(colour = "black"), axis.text.x = element_text(angle=90),
axis.text=element_text(size=15))+
scale_colour_viridis_d()+
theme(text = element_text(size = 25), plot.title = element_text(size=40))+
guides(color=guide_legend(title="Decade"))
plot(g)
p = ggplot(dt2, aes(x = rowname, y = colname, fill = value)) +
geom_tile(color = "white", aes(colour = NA))+
theme(panel.grid.minor = element_blank(),panel.background = element_blank(),
axis.line = element_line(colour = "black"), axis.text.x = element_text(angle=90),
axis.text=element_text(size=25))+
theme(text = element_text(size = 25), plot.title = element_text(size=40)) +
ggtitle("Same/Different decades as Text 1") +
xlab("Text 2") + ylab("Text 1") +
labs() +
scale_fill_continuous(low="white", high="black",guide="colorbar",na.value="white") +
guides(fill=guide_legend(title="AUC"))
plot(p)
library(igraph)
library(xtable)
library(dplyr)
library(dils)
library(xlsx)
#Setup
rm(list=ls())
mainpath = "C:/Users/Armin/Desktop/Data Science/CSH Project/Colex_vader/Armin/Output/"
setwd(paste0(mainpath, "Scripts"))
#Load networks
for (net in c("clics3_extended", "omegawiki_extended", "freedict_extended")) {
fname = sprintf('C:/Users/Armin/Desktop/Data Science/CSH Project/Colex_vader/filt_%s.Rda', net)
load(fname)
weight = "LanguageWeight"
network = network[,c("from_word", "to_word", weight)]
colnames(network) = c("from", "to", "weight")
network$from = as.character(network$from)
network$to = as.character(network$to)
network$weight = as.numeric(network$weight)
assign(net, network)
rm(network)
}
#Create combined network with clics3 network as a base
network = clics3_extended_new
allwords = c(unique(clics3_extended_new$from), unique(clics3_extended_new$to))
#Iterate through omegawiki network: If an edges both words are in clics3, add this edge
for (i in 1:nrow(omegawiki_extended)) {
currentrow = omegawiki_extended[i,]
if (currentrow$from %in% allwords & currentrow$to %in% allwords) {
network = rbind(network, currentrow)
}
}
#Iterate through freedict network: If an edges both words are in clics3, add this edge
for (i in 1:nrow(freedict_extended)) {
currentrow = freedict_extended[i,]
if (currentrow$from %in% allwords & currentrow$to %in% allwords) {
network = rbind(network, currentrow)
}
}
#Store net network
fname = sprintf('%s/Files/all_combined_clics3based.Rda', mainpath)
save(network, file = fname)
#Setup
rm(list=ls())
mainpath = "C:/Users/Armin/Desktop/Data Science/CSH Project/Colex_vader/Armin/Output/"
setwd(paste0(mainpath, "Scripts"))
paste0(mainpath, "Scripts")
library(igraph)
library(xtable)
library(dplyr)
library(dils)
library(xlsx)
#Setup
rm(list=ls())
mainpath = "C:/Users/Armin/Desktop/Data Science/CSH Project/Colex_vader/Output/"
setwd(paste0(mainpath, "Scripts"))
#Load networks
for (net in c("clics3_extended", "omegawiki_extended", "freedict_extended")) {
fname = sprintf('C:/Users/Armin/Desktop/Data Science/CSH Project/Colex_vader/filt_%s.Rda', net)
load(fname)
weight = "LanguageWeight"
network = network[,c("from_word", "to_word", weight)]
colnames(network) = c("from", "to", "weight")
network$from = as.character(network$from)
network$to = as.character(network$to)
network$weight = as.numeric(network$weight)
assign(net, network)
rm(network)
}
#Create combined network with clics3 network as a base
network = clics3_extended_new
allwords = c(unique(clics3_extended_new$from), unique(clics3_extended_new$to))
#Iterate through omegawiki network: If an edges both words are in clics3, add this edge
for (i in 1:nrow(omegawiki_extended)) {
currentrow = omegawiki_extended[i,]
if (currentrow$from %in% allwords & currentrow$to %in% allwords) {
network = rbind(network, currentrow)
}
}
#Iterate through freedict network: If an edges both words are in clics3, add this edge
for (i in 1:nrow(freedict_extended)) {
currentrow = freedict_extended[i,]
if (currentrow$from %in% allwords & currentrow$to %in% allwords) {
network = rbind(network, currentrow)
}
}
#Store net network
fname = sprintf('%s/Files/all_combined_clics3based.Rda', mainpath)
save(network, file = fname)
#Setup
rm(list=ls())
mainpath = "C:/Users/Armin/Desktop/Data Science/CSH Project/Colex_vader/Output/"
setwd(paste0(mainpath, "Scripts"))
library(igraph)
library(xtable)
library(dplyr)
library(dils)
library(xlsx)
#Setup
rm(list=ls())
mainpath = "C:/Users/Armin/Desktop/Data Science/CSH Project/Colex_vader/Output/"
setwd(paste0(mainpath, "Scripts"))
#Load networks
for (net in c("clics3_extended", "omegawiki_extended", "freedict_extended")) {
fname = sprintf('%s/Files/filt_%s.Rda', mainpath, net)
load(fname)
weight = "LanguageWeight"
network = network[,c("from_word", "to_word", weight)]
colnames(network) = c("from", "to", "weight")
network$from = as.character(network$from)
network$to = as.character(network$to)
network$weight = as.numeric(network$weight)
assign(net, network)
rm(network)
}
#Create combined network with clics3 network as a base
network = clics3_extended_new
allwords = c(unique(clics3_extended_new$from), unique(clics3_extended_new$to))
#Iterate through omegawiki network: If an edges both words are in clics3, add this edge
for (i in 1:nrow(omegawiki_extended)) {
currentrow = omegawiki_extended[i,]
if (currentrow$from %in% allwords & currentrow$to %in% allwords) {
network = rbind(network, currentrow)
}
}
#Iterate through freedict network: If an edges both words are in clics3, add this edge
for (i in 1:nrow(freedict_extended)) {
currentrow = freedict_extended[i,]
if (currentrow$from %in% allwords & currentrow$to %in% allwords) {
network = rbind(network, currentrow)
}
}
#Store net network
fname = sprintf('%s/Files/all_combined_clics3based.Rda', mainpath)
save(network, file = fname)
#Load networks
for (net in c("clics3_extended", "omegawiki_extended", "freedict_extended")) {
fname = sprintf('%s/Files/filt_%s.Rda', mainpath, net)
load(fname)
weight = "LanguageWeight"
network = network[,c("from_word", "to_word", weight)]
colnames(network) = c("from", "to", "weight")
network$from = as.character(network$from)
network$to = as.character(network$to)
network$weight = as.numeric(network$weight)
assign(net, network)
rm(network)
}
library(igraph)
library(xtable)
library(dplyr)
library(dils)
library(xlsx)
#Setup
rm(list=ls())
mainpath = "C:/Users/Armin/Desktop/Data Science/CSH Project/Colex_vader/Output/"
setwd(paste0(mainpath, "Scripts"))
#Load networks
for (net in c("clics3_extended", "omegawiki_extended", "freedict_extended")) {
fname = sprintf('%s/Files/filt_%s.Rda', mainpath, net)
load(fname)
weight = "LanguageWeight"
network = network[,c("from_word", "to_word", weight)]
colnames(network) = c("from", "to", "weight")
network$from = as.character(network$from)
network$to = as.character(network$to)
network$weight = as.numeric(network$weight)
assign(net, network)
rm(network)
}
#Create combined network with clics3 network as a base
network = clics3_extended_new
allwords = c(unique(clics3_extended_new$from), unique(clics3_extended_new$to))
#Iterate through omegawiki network: If an edges both words are in clics3, add this edge
for (i in 1:nrow(omegawiki_extended)) {
currentrow = omegawiki_extended[i,]
if (currentrow$from %in% allwords & currentrow$to %in% allwords) {
network = rbind(network, currentrow)
}
}
#Iterate through freedict network: If an edges both words are in clics3, add this edge
for (i in 1:nrow(freedict_extended)) {
currentrow = freedict_extended[i,]
if (currentrow$from %in% allwords & currentrow$to %in% allwords) {
network = rbind(network, currentrow)
}
}
#Store net network
fname = sprintf('%s/Files/all_combined_clics3based.Rda', mainpath)
save(network, file = fname)
library(igraph)
library(xtable)
library(dplyr)
library(dils)
library(xlsx)
#Setup
rm(list=ls())
mainpath = "C:/Users/Armin/Desktop/Data Science/CSH Project/Colex_vader/Output/"
setwd(paste0(mainpath, "Scripts"))
#Load networks
for (net in c("clics3_extended", "omegawiki_extended", "freedict_extended")) {
fname = sprintf('%s/Files/filt_%s.Rda', mainpath, net)
load(fname)
weight = "LanguageWeight"
network = network[,c("from_word", "to_word", weight)]
colnames(network) = c("from", "to", "weight")
network$from = as.character(network$from)
network$to = as.character(network$to)
network$weight = as.numeric(network$weight)
assign(net, network)
rm(network)
}
#Create combined network with clics3 network as a base
network = clics3_extended_new
library(igraph)
library(xtable)
library(dplyr)
library(dils)
library(xlsx)
#Setup
rm(list=ls())
mainpath = "C:/Users/Armin/Desktop/Data Science/CSH Project/Colex_vader/Output/"
setwd(paste0(mainpath, "Scripts"))
#Load networks
for (net in c("clics3_extended", "omegawiki_extended", "freedict_extended")) {
fname = sprintf('%s/Files/filt_%s.Rda', mainpath, net)
load(fname)
weight = "LanguageWeight"
network = network[,c("from_word", "to_word", weight)]
colnames(network) = c("from", "to", "weight")
network$from = as.character(network$from)
network$to = as.character(network$to)
network$weight = as.numeric(network$weight)
assign(net, network)
rm(network)
}
#Create combined network with clics3 network as a base
network = clics3_extended
allwords = c(unique(clics3_extended$from), unique(clics3_extended$to))
#Iterate through omegawiki network: If an edges both words are in clics3, add this edge
for (i in 1:nrow(omegawiki_extended)) {
currentrow = omegawiki_extended[i,]
if (currentrow$from %in% allwords & currentrow$to %in% allwords) {
network = rbind(network, currentrow)
}
}
#Iterate through freedict network: If an edges both words are in clics3, add this edge
for (i in 1:nrow(freedict_extended)) {
currentrow = freedict_extended[i,]
if (currentrow$from %in% allwords & currentrow$to %in% allwords) {
network = rbind(network, currentrow)
}
}
#Store net network
fname = sprintf('%s/Files/all_combined_clics3based.Rda', mainpath)
save(network, file = fname)
library(igraph)
library(xtable)
library(dplyr)
library(dils)
library(xlsx)
#Setup
rm(list=ls())
mainpath = "C:/Users/Armin/Desktop/Data Science/CSH Project/Colex_vader/Output/"
setwd(paste0(mainpath, "Scripts"))
#Load networks
for (net in c("clics3_extended", "omegawiki_extended", "freedict_extended")) {
fname = sprintf('%s/Files/filt_%s.Rda', mainpath, net)
load(fname)
weight = "LanguageWeight"
network = network[,c("from_word", "to_word", weight)]
colnames(network) = c("from", "to", "weight")
network$from = as.character(network$from)
network$to = as.character(network$to)
network$weight = as.numeric(network$weight)
assign(net, network)
rm(network)
}
#Create combined network with clics3 network as a base
network = clics3_extended
allwords = c(unique(clics3_extended$from), unique(clics3_extended$to))
#Iterate through omegawiki network: If an edges both words are in clics3, add this edge
for (i in 1:nrow(omegawiki_extended)) {
currentrow = omegawiki_extended[i,]
if (currentrow$from %in% allwords & currentrow$to %in% allwords) {
network = rbind(network, currentrow)
}
}
#Iterate through freedict network: If an edges both words are in clics3, add this edge
for (i in 1:nrow(freedict_extended)) {
currentrow = freedict_extended[i,]
if (currentrow$from %in% allwords & currentrow$to %in% allwords) {
network = rbind(network, currentrow)
}
}
#Store net network
fname = sprintf('%s/Files/combined_clics3based.Rda', mainpath)
save(network, file = fname)
library(igraph)
library(xtable)
library(dplyr)
library(dils)
library(xlsx)
rm(list=ls())
mainpath = "C:/Users/Armin/Desktop/Data Science/CSH Project/Colex_vader/Output/"
setwd(paste0(mainpath,"Scripts"))
net = "combined_clics3based"
fname = sprintf('%sFiles/%s.Rda', mainpath,net)
#Load network
net = "combined_clics3based"
fname = sprintf('%sFiles/%s.Rda', mainpath,net)
network = readRDS(fname)
load(fname)
network_orig = network
library(igraph)
library(xtable)
library(dplyr)
library(dils)
library(xlsx)
#Setup path
rm(list=ls())
mainpath = "C:/Users/Armin/Desktop/Data Science/CSH Project/Colex_vader/Output/"
setwd(paste0(mainpath,"Scripts"))
#Load network
net = "combined_clics3based"
fname = sprintf('%sFiles/%s.Rda', mainpath,net)
load(fname)
network_orig = network
#Select and format columns
weight = "LanguageWeight"
network = network[,c("from_word", "to_word", weight)]
network$weight = as.numeric(network$weight)
colnames(network) = c("from", "to", "weight")
#Create igraph graph
g=graph.data.frame(network)
#Get adjacency matrix
adjmat = get.adjacency(g,sparse=FALSE, attr='weight')
nodelist = colnames(adjmat)
colnames(adjmat) = nodelist
rownames(adjmat) = nodelist
for (i in 1:nrow(adjmat)) {
adjmat[i,i] = sum(adjmat[i,]) + sum(adjmat[,i])
}
#Loop over different beta values
betalist = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8 ,0.9)
source('C:/Users/Armin/Desktop/Data Science/CSH Project/Colex_vader/Armin/Scripts/similarities_from_adjacency.R')
for (beta in betalist) {
#Run it with normal adjacency matrix
result1 = similarities_from_adjacency(adjmat, beta)
result2 = similarities_from_adjacency(t(adjmat), beta)
result = (result1 + result2)*0.5
colnames(result) = nodelist
rownames(result) = nodelist
storename = sprintf("%s/Similarities/%s/simil_list_beta_%s.csv",mainpath, net, beta)
write.csv(result, storename)
}
library(igraph)
library(xtable)
library(dplyr)
library(dils)
library(xlsx)
#Setup path
rm(list=ls())
mainpath = "C:/Users/Armin/Desktop/Data Science/CSH Project/Colex_vader/Output/"
setwd(paste0(mainpath,"Scripts"))
#Load network
net = "combined_clics3based"
fname = sprintf('%sFiles/%s.Rda', mainpath,net)
load(fname)
network_orig = network
#Select and format columns
weight = "LanguageWeight"
network = network[,c("from_word", "to_word", weight)]
network$weight = as.numeric(network$weight)
colnames(network) = c("from", "to", "weight")
#Create igraph graph
g=graph.data.frame(network)
#Get adjacency matrix
adjmat = get.adjacency(g,sparse=FALSE, attr='weight')
nodelist = colnames(adjmat)
colnames(adjmat) = nodelist
rownames(adjmat) = nodelist
for (i in 1:nrow(adjmat)) {
adjmat[i,i] = sum(adjmat[i,]) + sum(adjmat[,i])
}
#Loop over different beta values
betalist = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8 ,0.9)
source('C:/Users/Armin/Desktop/Data Science/CSH Project/Colex_vader/Armin/Scripts/similarities_from_adjacency.R')
for (beta in betalist) {
#Run it with normal adjacency matrix
result1 = similarities_from_adjacency(adjmat, beta)
result2 = similarities_from_adjacency(t(adjmat), beta)
result = (result1 + result2)*0.5
colnames(result) = nodelist
rownames(result) = nodelist
storename = sprintf("%s/Similarities/%s/simil_list_beta_%s.csv",mainpath, net, beta)
write.csv(result, storename)
}
library(igraph)
library(xtable)
library(dplyr)
library(dils)
library(xlsx)
#Setup path
rm(list=ls())
mainpath = "C:/Users/Armin/Desktop/Data Science/CSH Project/Colex_vader/Output/"
setwd(paste0(mainpath,"Scripts"))
#Load network
net = "combined_clics3based"
fname = sprintf('%sFiles/%s.Rda', mainpath,net)
load(fname)
network_orig = network
#Select and format columns
weight = "LanguageWeight"
network = network[,c("from_word", "to_word", weight)]
network$weight = as.numeric(network$weight)
colnames(network) = c("from", "to", "weight")
#Create igraph graph
g=graph.data.frame(network)
#Get adjacency matrix
adjmat = get.adjacency(g,sparse=FALSE, attr='weight')
nodelist = colnames(adjmat)
colnames(adjmat) = nodelist
rownames(adjmat) = nodelist
for (i in 1:nrow(adjmat)) {
adjmat[i,i] = sum(adjmat[i,]) + sum(adjmat[,i])
}
#Loop over different beta values
betalist = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8 ,0.9)
source('C:/Users/Armin/Desktop/Data Science/CSH Project/Colex_vader/Armin/Scripts/similarities_from_adjacency.R')
for (beta in betalist) {
#Run it with normal adjacency matrix
result1 = similarities_from_adjacency(adjmat, beta)
result2 = similarities_from_adjacency(t(adjmat), beta)
result = (result1 + result2)*0.5
colnames(result) = nodelist
rownames(result) = nodelist
storename = sprintf("%sSimilarities/%s/simil_list_beta_%s.csv",mainpath, net, beta)
write.csv(result, storename)
}
library(igraph)
library(xtable)
library(dplyr)
library(dils)
library(xlsx)
#Setup path
rm(list=ls())
mainpath = "C:/Users/Armin/Desktop/Data Science/CSH Project/Colex_vader/Output/"
setwd(paste0(mainpath,"Scripts"))
#Load network
net = "combined_clics3based"
fname = sprintf('%sFiles/%s.Rda', mainpath,net)
load(fname)
network_orig = network
#Select and format columns
weight = "LanguageWeight"
network = network[,c("from_word", "to_word", weight)]
network$weight = as.numeric(network$weight)
colnames(network) = c("from", "to", "weight")
#Create igraph graph
g=graph.data.frame(network)
#Get adjacency matrix
adjmat = get.adjacency(g,sparse=FALSE, attr='weight')
nodelist = colnames(adjmat)
colnames(adjmat) = nodelist
rownames(adjmat) = nodelist
for (i in 1:nrow(adjmat)) {
adjmat[i,i] = sum(adjmat[i,]) + sum(adjmat[,i])
}
#Loop over different beta values
betalist = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8 ,0.9)
source('C:/Users/Armin/Desktop/Data Science/CSH Project/Colex_vader/Armin/Scripts/similarities_from_adjacency.R')
for (beta in betalist) {
#Run it with normal adjacency matrix
result1 = similarities_from_adjacency(adjmat, beta)
result2 = similarities_from_adjacency(t(adjmat), beta)
result = (result1 + result2)*0.5
colnames(result) = nodelist
rownames(result) = nodelist
storename = sprintf("%sSimilarities/simil_list_beta_%s.csv",mainpath, beta)
write.csv(result, storename)
}
