for (i in 1:nrow(freedict_extended)) {
currentrow = freedict_extended[i,]
if (currentrow$from %in% allwords & currentrow$to %in% allwords) {
network = rbind(network, currentrow)
}
}
#Store net network
fname = sprintf('%s/Files/combined_clics3based.Rda', mainpath)
save(network, file = fname)
library(igraph)
library(xtable)
library(dplyr)
library(dils)
library(xlsx)
#Setup
rm(list=ls())
mainpath = "C:/Users/Armin/Desktop/Data Science/CSH Project/Colex_vader/Output/"
setwd(paste0(mainpath, "Scripts"))
library(igraph)
library(xtable)
library(dplyr)
library(dils)
library(xlsx)
#Setup
rm(list=ls())
mainpath = "C:/Users/Armin/Desktop/Data Science/CSH Project/Colex_vader/Output/"
setwd(paste0(mainpath, "Scripts"))
#Load networks
for (net in c("clics3_extended", "omegawiki_extended", "freedict_extended")) {
fname = sprintf('%sFiles/filt_%s.Rda', mainpath, net)
load(fname)
weight = "LanguageWeight"
network = network[,c("from_word", "to_word", weight)]
colnames(network) = c("from", "to", "weight")
network$from = as.character(network$from)
network$to = as.character(network$to)
network$weight = as.numeric(network$weight)
assign(net, network)
rm(network)
}
#Create combined network with clics3 network as a base
network = clics3_extended
allwords = c(unique(clics3_extended$from), unique(clics3_extended$to))
#Iterate through omegawiki network: If an edges both words are in clics3, add this edge
for (i in 1:nrow(omegawiki_extended)) {
currentrow = omegawiki_extended[i,]
if (currentrow$from %in% allwords & currentrow$to %in% allwords) {
network = rbind(network, currentrow)
}
}
#Iterate through freedict network: If an edges both words are in clics3, add this edge
for (i in 1:nrow(freedict_extended)) {
currentrow = freedict_extended[i,]
if (currentrow$from %in% allwords & currentrow$to %in% allwords) {
network = rbind(network, currentrow)
}
}
#Store net network
fname = sprintf('%s/Files/combined_clics3based.Rda', mainpath)
save(network, file = fname)
View(network)
library(igraph)
library(xtable)
library(dplyr)
library(dils)
library(xlsx)
#Setup
rm(list=ls())
mainpath = "C:/Users/Armin/Desktop/Data Science/CSH Project/Colex_vader/Output/"
setwd(paste0(mainpath, "Scripts"))
#Load networks
for (net in c("clics3_extended", "omegawiki_extended", "freedict_extended")) {
fname = sprintf('%sFiles/filt_%s.Rda', mainpath, net)
load(fname)
weight = "LanguageWeight"
network = network[,c("from_word", "to_word", weight)]
colnames(network) = c("from", "to", "weight")
network$from = as.character(network$from)
network$to = as.character(network$to)
network$weight = as.numeric(network$weight)
assign(net, network)
rm(network)
}
#Create combined network with clics3 network as a base
network = clics3_extended
#Remove all "(" and ")"
network$from = gsub('(',' ',network$from)
network$to = gsub('(',' ',network$to)
allwords = c(unique(clics3_extended$from), unique(clics3_extended$to))
#Iterate through omegawiki network: If an edges both words are in clics3, add this edge
for (i in 1:nrow(omegawiki_extended)) {
currentrow = omegawiki_extended[i,]
if (currentrow$from %in% allwords & currentrow$to %in% allwords) {
network = rbind(network, currentrow)
}
}
#Iterate through freedict network: If an edges both words are in clics3, add this edge
for (i in 1:nrow(freedict_extended)) {
currentrow = freedict_extended[i,]
if (currentrow$from %in% allwords & currentrow$to %in% allwords) {
network = rbind(network, currentrow)
}
}
#Store net network
fname = sprintf('%s/Files/combined_clics3based.Rda', mainpath)
save(network, file = fname)
library(igraph)
library(xtable)
library(dplyr)
library(dils)
library(xlsx)
#Setup
rm(list=ls())
mainpath = "C:/Users/Armin/Desktop/Data Science/CSH Project/Colex_vader/Output/"
setwd(paste0(mainpath, "Scripts"))
#Load networks
for (net in c("clics3_extended", "omegawiki_extended", "freedict_extended")) {
fname = sprintf('%sFiles/filt_%s.Rda', mainpath, net)
load(fname)
weight = "LanguageWeight"
network = network[,c("from_word", "to_word", weight)]
colnames(network) = c("from", "to", "weight")
network$from = as.character(network$from)
network$to = as.character(network$to)
network$weight = as.numeric(network$weight)
assign(net, network)
rm(network)
}
#Create combined network with clics3 network as a base
network = clics3_extended
#Remove all "(" and ")"
network$from = gsub("\\s*\\([^\\)]+\\)","",as.character(network$from))
network$to = gsub("\\s*\\([^\\)]+\\)","",as.character(network$to))
allwords = c(unique(clics3_extended$from), unique(clics3_extended$to))
#Iterate through omegawiki network: If an edges both words are in clics3, add this edge
for (i in 1:nrow(omegawiki_extended)) {
currentrow = omegawiki_extended[i,]
if (currentrow$from %in% allwords & currentrow$to %in% allwords) {
network = rbind(network, currentrow)
}
}
#Iterate through freedict network: If an edges both words are in clics3, add this edge
for (i in 1:nrow(freedict_extended)) {
currentrow = freedict_extended[i,]
if (currentrow$from %in% allwords & currentrow$to %in% allwords) {
network = rbind(network, currentrow)
}
}
#Store net network
fname = sprintf('%s/Files/combined_clics3based.Rda', mainpath)
save(network, file = fname)
View(network)
library(igraph)
library(xtable)
library(dplyr)
library(dils)
library(xlsx)
#Setup
rm(list=ls())
mainpath = "C:/Users/Armin/Desktop/Data Science/CSH Project/Colex_vader/Output/"
setwd(paste0(mainpath, "Scripts"))
#Load networks
for (net in c("clics3_extended", "omegawiki_extended", "freedict_extended")) {
fname = sprintf('%sFiles/filt_%s.Rda', mainpath, net)
load(fname)
weight = "LanguageWeight"
network = network[,c("from_word", "to_word", weight)]
colnames(network) = c("from", "to", "weight")
network$from = as.character(network$from)
network$to = as.character(network$to)
network$weight = as.numeric(network$weight)
assign(net, network)
rm(network)
}
#Create combined network with clics3 network as a base
network = clics3_extended
#Remove all "(" and ")"
network$from = gsub("\\s*\\([^\\)]+\\)","",as.character(network$from))
network$to = gsub("\\s*\\([^\\)]+\\)","",as.character(network$to))
allwords = c(unique(network$from), unique(network$to))
#Iterate through omegawiki network: If an edges both words are in clics3, add this edge
for (i in 1:nrow(omegawiki_extended)) {
currentrow = omegawiki_extended[i,]
if (currentrow$from %in% allwords & currentrow$to %in% allwords) {
network = rbind(network, currentrow)
}
}
#Iterate through freedict network: If an edges both words are in clics3, add this edge
for (i in 1:nrow(freedict_extended)) {
currentrow = freedict_extended[i,]
if (currentrow$from %in% allwords & currentrow$to %in% allwords) {
network = rbind(network, currentrow)
}
}
#Store net network
fname = sprintf('%s/Files/combined_clics3based.Rda', mainpath)
save(network, file = fname)
View(network)
gsub("\\s*\\([^\\)]+\\)","",as.character(network$from))
library(igraph)
library(xtable)
library(dplyr)
library(dils)
library(xlsx)
#Setup
rm(list=ls())
mainpath = "C:/Users/Armin/Desktop/Data Science/CSH Project/Colex_vader/Output/"
setwd(paste0(mainpath, "Scripts"))
#Load networks
for (net in c("clics3_extended", "omegawiki_extended", "freedict_extended")) {
fname = sprintf('%sFiles/filt_%s.Rda', mainpath, net)
load(fname)
weight = "LanguageWeight"
network = network[,c("from_word", "to_word", weight)]
colnames(network) = c("from", "to", "weight")
network$from = as.character(network$from)
network$to = as.character(network$to)
network$weight = as.numeric(network$weight)
assign(net, network)
rm(network)
}
#Create combined network with clics3 network as a base
network = clics3_extended
#Remove all "(" and ")"
network$from = gsub(paste(c("[(]", "[)]"), collapse = "|"), "", network$from)
network$to = gsub(paste(c("[(]", "[)]"), collapse = "|"), "", network$to)
allwords = c(unique(network$from), unique(network$to))
#Iterate through omegawiki network: If an edges both words are in clics3, add this edge
for (i in 1:nrow(omegawiki_extended)) {
currentrow = omegawiki_extended[i,]
if (currentrow$from %in% allwords & currentrow$to %in% allwords) {
network = rbind(network, currentrow)
}
}
#Iterate through freedict network: If an edges both words are in clics3, add this edge
for (i in 1:nrow(freedict_extended)) {
currentrow = freedict_extended[i,]
if (currentrow$from %in% allwords & currentrow$to %in% allwords) {
network = rbind(network, currentrow)
}
}
#Store net network
fname = sprintf('%s/Files/combined_clics3based.Rda', mainpath)
save(network, file = fname)
View(network)
similarities_from_adjacency = function(adjmat, beta) {
#Compute similarity matrix from adjacency matrix
library(reticulate)
norm = scale(adjmat, center = FALSE, scale = colSums(adjmat))
ones = matrix(0, nrow(adjmat), ncol(adjmat))
diag(ones) = 1
before_inv = ones - beta * norm
write.table(before_inv, "before_inv.csv", row.names = FALSE, col.names = FALSE, sep = ",")
#Run python script
print('Run python script')
use_python("C:\Users\Armin\AppData\Local\Programs\Python\Python36-32\python.exe", required = T)
py_run_file("Networks/Invert.py")
inverse = data.matrix(read.csv("after_inv.csv", header = FALSE))
#Compute similarities
print('Compute similarities')
result = inverse %*% norm
file.remove("before_inv.csv")
file.remove("after_inv.csv")
return(result)
}
similarities_from_adjacency = function(adjmat, beta) {
#Compute similarity matrix from adjacency matrix
library(reticulate)
norm = scale(adjmat, center = FALSE, scale = colSums(adjmat))
ones = matrix(0, nrow(adjmat), ncol(adjmat))
diag(ones) = 1
before_inv = ones - beta * norm
write.table(before_inv, "before_inv.csv", row.names = FALSE, col.names = FALSE, sep = ",")
#Run python script
print('Run python script')
use_python("C:/Users/Armin/AppData/Local/Programs/Python/Python36-32/python.exe", required = T)
py_run_file("Networks/Invert.py")
inverse = data.matrix(read.csv("after_inv.csv", header = FALSE))
#Compute similarities
print('Compute similarities')
result = inverse %*% norm
file.remove("before_inv.csv")
file.remove("after_inv.csv")
return(result)
}
library(igraph)
library(xtable)
library(dplyr)
library(dils)
library(xlsx)
#Setup path
rm(list=ls())
mainpath = "C:/Users/Armin/Desktop/Data Science/CSH Project/Colex_vader/Output/"
setwd(paste0(mainpath,"Scripts"))
#Load network
net = "combined_clics3based"
fname = sprintf('%sFiles/%s.Rda', mainpath,net)
load(fname)
network_orig = network
#Select and format columns
weight = "LanguageWeight"
network = network[,c("from_word", "to_word", weight)]
network$weight = as.numeric(network$weight)
colnames(network) = c("from", "to", "weight")
#Create igraph graph
g=graph.data.frame(network)
#Get adjacency matrix
adjmat = get.adjacency(g,sparse=FALSE, attr='weight')
nodelist = colnames(adjmat)
colnames(adjmat) = nodelist
rownames(adjmat) = nodelist
#Diagonal entries are self loops -> sum of all ingoing and outgiong edges
for (i in 1:nrow(adjmat)) {
adjmat[i,i] = sum(adjmat[i,]) + sum(adjmat[,i])
}
#Loop over different beta values
betalist = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8 ,0.9)
#Load script where inverting happens
source('Networks/similarities_from_adjacency.R')
for (beta in betalist) {
#Run computation is other script
result1 = similarities_from_adjacency(adjmat, beta)
result2 = similarities_from_adjacency(t(adjmat), beta)
result = (result1 + result2)*0.5
colnames(result) = nodelist
rownames(result) = nodelist
#Store resulting adjacency matrices
storename = sprintf("%sSimilarities/simil_list_beta_%s.csv",mainpath, beta)
write.csv(result, storename)
}
reticulate::install_miniconda()
library(igraph)
library(xtable)
library(dplyr)
library(dils)
library(xlsx)
#Setup path
rm(list=ls())
mainpath = "C:/Users/Armin/Desktop/Data Science/CSH Project/Colex_vader/Output/"
setwd(paste0(mainpath,"Scripts"))
#Load network
net = "combined_clics3based"
fname = sprintf('%sFiles/%s.Rda', mainpath,net)
load(fname)
network_orig = network
#Select and format columns
weight = "LanguageWeight"
network = network[,c("from_word", "to_word", weight)]
network$weight = as.numeric(network$weight)
colnames(network) = c("from", "to", "weight")
#Create igraph graph
g=graph.data.frame(network)
#Get adjacency matrix
adjmat = get.adjacency(g,sparse=FALSE, attr='weight')
nodelist = colnames(adjmat)
colnames(adjmat) = nodelist
rownames(adjmat) = nodelist
#Diagonal entries are self loops -> sum of all ingoing and outgiong edges
for (i in 1:nrow(adjmat)) {
adjmat[i,i] = sum(adjmat[i,]) + sum(adjmat[,i])
}
#Loop over different beta values
betalist = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8 ,0.9)
#Load script where inverting happens
source('Networks/similarities_from_adjacency.R')
for (beta in betalist) {
#Run computation is other script
result1 = similarities_from_adjacency(adjmat, beta)
result2 = similarities_from_adjacency(t(adjmat), beta)
result = (result1 + result2)*0.5
colnames(result) = nodelist
rownames(result) = nodelist
#Store resulting adjacency matrices
storename = sprintf("%sSimilarities/simil_list_beta_%s.csv",mainpath, beta)
write.csv(result, storename)
}
library(igraph)
library(xtable)
library(dplyr)
library(dils)
library(xlsx)
#Setup path
rm(list=ls())
mainpath = "C:/Users/Armin/Desktop/Data Science/CSH Project/Colex_vader/Output/"
setwd(paste0(mainpath,"Scripts"))
#Load network
net = "combined_clics3based"
fname = sprintf('%sFiles/%s.Rda', mainpath,net)
load(fname)
network_orig = network
#Select and format columns
weight = "LanguageWeight"
network = network[,c("from_word", "to_word", weight)]
network$weight = as.numeric(network$weight)
colnames(network) = c("from", "to", "weight")
#Create igraph graph
g=graph.data.frame(network)
#Get adjacency matrix
adjmat = get.adjacency(g,sparse=FALSE, attr='weight')
nodelist = colnames(adjmat)
colnames(adjmat) = nodelist
rownames(adjmat) = nodelist
#Diagonal entries are self loops -> sum of all ingoing and outgiong edges
for (i in 1:nrow(adjmat)) {
adjmat[i,i] = sum(adjmat[i,]) + sum(adjmat[,i])
}
#Loop over different beta values
betalist = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8 ,0.9)
#Load script where inverting happens
source('Networks/similarities_from_adjacency.R')
for (beta in betalist) {
#Run computation is other script
result1 = similarities_from_adjacency(adjmat, beta)
result2 = similarities_from_adjacency(t(adjmat), beta)
result = (result1 + result2)*0.5
colnames(result) = nodelist
rownames(result) = nodelist
#Store resulting adjacency matrices
storename = sprintf("%sSimilarities/simil_list_beta_%s.csv",mainpath, beta)
write.csv(result, storename)
}
library(igraph)
library(xtable)
library(dplyr)
library(dils)
library(xlsx)
#Setup path
rm(list=ls())
mainpath = "C:/Users/Armin/Desktop/Data Science/CSH Project/Colex_vader/Output/"
setwd(paste0(mainpath,"Scripts"))
#Load network
net = "combined_clics3based"
fname = sprintf('%sFiles/%s.Rda', mainpath,net)
load(fname)
network_orig = network
#Select and format columns
weight = "LanguageWeight"
network = network[,c("from_word", "to_word", weight)]
network$weight = as.numeric(network$weight)
colnames(network) = c("from", "to", "weight")
#Create igraph graph
g=graph.data.frame(network)
#Get adjacency matrix
adjmat = get.adjacency(g,sparse=FALSE, attr='weight')
nodelist = colnames(adjmat)
colnames(adjmat) = nodelist
rownames(adjmat) = nodelist
#Diagonal entries are self loops -> sum of all ingoing and outgiong edges
for (i in 1:nrow(adjmat)) {
adjmat[i,i] = sum(adjmat[i,]) + sum(adjmat[,i])
}
#Loop over different beta values
betalist = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8 ,0.9)
#Load script where inverting happens
source('Networks/similarities_from_adjacency.R')
for (beta in betalist) {
#Run computation is other script
result1 = similarities_from_adjacency(adjmat, beta)
result2 = similarities_from_adjacency(t(adjmat), beta)
result = (result1 + result2)*0.5
colnames(result) = nodelist
rownames(result) = nodelist
#Store resulting adjacency matrices
storename = sprintf("%sSimilarities/simil_list_beta_%s.csv",mainpath, beta)
write.csv(result, storename)
}
library(igraph)
library(xtable)
library(dplyr)
library(dils)
library(xlsx)
#Setup path
rm(list=ls())
mainpath = "C:/Users/Armin/Desktop/Data Science/CSH Project/Colex_vader/Output/"
setwd(paste0(mainpath,"Scripts"))
#Load network
net = "combined_clics3based"
fname = sprintf('%sFiles/%s.Rda', mainpath,net)
load(fname)
network_orig = network
#Select and format columns
weight = "LanguageWeight"
network = network[,c("from_word", "to_word", weight)]
network$weight = as.numeric(network$weight)
colnames(network) = c("from", "to", "weight")
#Create igraph graph
g=graph.data.frame(network)
#Get adjacency matrix
adjmat = get.adjacency(g,sparse=FALSE, attr='weight')
nodelist = colnames(adjmat)
colnames(adjmat) = nodelist
rownames(adjmat) = nodelist
#Diagonal entries are self loops -> sum of all ingoing and outgiong edges
for (i in 1:nrow(adjmat)) {
adjmat[i,i] = sum(adjmat[i,]) + sum(adjmat[,i])
}
#Loop over different beta values
betalist = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8 ,0.9)
#Load script where inverting happens
source('Networks/similarities_from_adjacency.R')
for (beta in betalist) {
#Run computation is other script
result1 = similarities_from_adjacency(adjmat, beta)
result2 = similarities_from_adjacency(t(adjmat), beta)
result = (result1 + result2)*0.5
colnames(result) = nodelist
rownames(result) = nodelist
#Store resulting adjacency matrices
storename = sprintf("%sSimilarities/simil_list_beta_%s.csv",mainpath, beta)
write.csv(result, storename)
}
View(network)
